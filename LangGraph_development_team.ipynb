{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade langchain langsmith langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OPENAI_API_KEY from .env file\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "#os.environ[\"OPENAI_ORGANIZATION\"] = os.getenv(\"OPENAI_ORGANIZATION\")\n",
    "\n",
    "# Initialize LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Agent Demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queary a collection to find some code examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'weaviate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mweaviate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[0;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m Client(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:8080\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_collection\u001b[39m(query):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'weaviate'"
     ]
    }
   ],
   "source": [
    "from weaviate import Client\n",
    "\n",
    "client = Client(\"http://localhost:8080\")\n",
    "\n",
    "\n",
    "def query_collection(query):\n",
    "    response = (\n",
    "        client.query.get(\"code_example\", [\"code\"])\n",
    "        .with_near_text({\"concepts\": [query]})\n",
    "        .with_limit(3)\n",
    "        .do()\n",
    "    )\n",
    "\n",
    "    formatted_response = \"\"\n",
    "    for result in response[\"data\"][\"Get\"][\"Code_example\"]:\n",
    "        formatted_response += \"# Example:\\n\"\n",
    "        formatted_response += f\"{result['code']}\\n\\n\\n\"\n",
    "\n",
    "    return formatted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# Set up the system template with a variable for context\n",
    "system_template = \"\"\"\n",
    "Generate working code for a Jupyter Notebook based on the user's request. Your code should use LangChain, and specifically use LangChain's Expression Language in structuring your code.\n",
    "\n",
    "Strictly adhere to the code examples delimited by triple backticks below as context for how LangChain's API works. DO NOT use any patterns that you do not find in the example below, unless you are 100% certain they work in LangChain:\n",
    "\n",
    "```\n",
    "{context}\n",
    "```\n",
    "\n",
    "Before sharing, double check your work. I will tip you $100 if your code is perfect.\n",
    "\n",
    "Do not explain your work, just share working code.\n",
    "\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# Set up the human template with a variable for the request\n",
    "human_template = \"\"\"\n",
    "{request}\n",
    "\"\"\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "code_writing_runnable = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up the agent's tools\n",
    "\n",
    "tools = []\n",
    "pseudo_tools_visible = [\n",
    "    \"Retrieve Context\",\n",
    "    \"Write Code\",\n",
    "    \"Review Code\",\n",
    "    # \"Save Code\",\n",
    "]\n",
    "pseudo_tools_hidden = [\n",
    "    \"Store Request\",\n",
    "] \n",
    "\n",
    "agent_tools = tools + pseudo_tools_visible + pseudo_tools_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom tool for routing Agent - superviser agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StructuredTool\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Set the agent options, which is FINISH plus all tools, with the exception of the hidden tools\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m agent_options \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINISH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43magent_tools\u001b[49m\n\u001b[0;32m      8\u001b[0m agent_options \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m agent_options \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pseudo_tools_hidden]\n\u001b[0;32m     10\u001b[0m RouteOptions \u001b[38;5;241m=\u001b[39m Enum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRouteOptions\u001b[39m\u001b[38;5;124m\"\u001b[39m, {option: option \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m agent_options})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_tools' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel\n",
    "from enum import Enum\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "\n",
    "# Set the agent options, which is FINISH plus all tools, with the exception of the hidden tools\n",
    "agent_options = [\"FINISH\"] + agent_tools\n",
    "agent_options = [item for item in agent_options if item not in pseudo_tools_hidden]\n",
    "\n",
    "RouteOptions = Enum(\"RouteOptions\", {option: option for option in agent_options})\n",
    "\n",
    "\n",
    "class RouteInput(BaseModel):\n",
    "    next: RouteOptions\n",
    "\n",
    "\n",
    "def route(route: str) -> str:\n",
    "    return route\n",
    "\n",
    "#Select next team member to use \n",
    "router = StructuredTool.from_function(\n",
    "    func=route,\n",
    "    name=\"route\",\n",
    "    description=\"Select the next team member to use\",\n",
    "    args_schema=RouteInput,\n",
    "    return_direct=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m\n\u001b[0;32m      9\u001b[0m system_prompt_initial \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124mYou are a supervisor tasked with managing a development team consisting of the following members: \u001b[39m\u001b[38;5;132;01m{members}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m     11\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m3) Save the code you have written once the reviewer has approved the code\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Get the prompt to use - you can modify this!\u001b[39;00m\n\u001b[0;32m     24\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[0;32m     25\u001b[0m     [\n\u001b[0;32m     26\u001b[0m         SystemMessagePromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(system_prompt_initial),\n\u001b[0;32m     27\u001b[0m         MessagesPlaceholder(variable_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     28\u001b[0m         MessagesPlaceholder(variable_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     29\u001b[0m     ]\n\u001b[1;32m---> 30\u001b[0m )\u001b[38;5;241m.\u001b[39mpartial(options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[43magent_options\u001b[49m), members\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(agent_tools))\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Choose the LLM that will drive the agent\u001b[39;00m\n\u001b[0;32m     33\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-1106\u001b[39m\u001b[38;5;124m\"\u001b[39m, streaming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_options' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "#System prompt for supervisor \n",
    "system_prompt_initial = \"\"\"\n",
    "You are a supervisor tasked with managing a development team consisting of the following members: {members}.\n",
    "\n",
    "Given the following feature request from a user, respond with the worker to act next.\n",
    "\n",
    "Each worker will perform a task and respond with their results and status. This task is complete as soon as you know a worker has retrieved context related to the user's feature request. When the task is complete, respond with FINISH.\n",
    "\n",
    "You typically follow this pattern:\n",
    "\n",
    "1) Retrieve context related to the user's query. This is a REQUIRED step before writing code\n",
    "2) Write code to solve the problem\n",
    "3) Save the code you have written once the reviewer has approved the code\n",
    "\"\"\"\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt_initial),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ").partial(options=str(agent_options), members=\", \".join(agent_tools))\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", streaming=True)\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm, [router], prompt) #(llm, tools , prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence, Union\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The list of previous messages in the conversation\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The outcome of a given call to the agent\n",
    "    # Needs `None` as a valid type, since this is what this will start as\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    # List of actions and corresponding observations\n",
    "    # Here we annotate this with `operator.add` to indicate that operations to\n",
    "    # this state should be ADDED to the existing values (not overwrite it)\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n",
    "    # The user's original request\n",
    "    original_request: str\n",
    "    # The context for code writing\n",
    "    context: str\n",
    "    # The code sample being generated.\n",
    "    #We want it to be stored and never passed around <--> takes a lot of tokens\n",
    "    code: str\n",
    "    # Track whether the code hsa been approved\n",
    "    code_approved: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the node actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage, AIMessage\n",
    "\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    if isinstance(state[\"agent_outcome\"], AgentFinish):\n",
    "        return \"end\"\n",
    "    # Otherwise, an AgentAction is returned\n",
    "    # Here we return `continue` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    # messages = state['messages']\n",
    "    agent_outcome = agent_runnable.invoke(state)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "\n",
    "def call_set_initial_state(state):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    return {\"original_request\": last_message.content}\n",
    "\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    tool = state['agent_outcome'].tool_input['next']\n",
    "    print(\"Running Tool: \", tool)\n",
    "\n",
    "    if tool == \"Retrieve Context\":\n",
    "        print(\"Retreive Context\")\n",
    "        context = query_collection(state[\"original_request\"])\n",
    "        new_message = AIMessage(content=\"You have context now\")\n",
    "        return {\"context\": context, \"messages\": [new_message]}\n",
    "    elif tool == \"Write Code\":\n",
    "        print(\"successfully writing code now\")\n",
    "        code_writing_runnable.invoke({\"context\": state[\"context\"], \"request\": state[\"original_request\"]})\n",
    "        new_message = AIMessage(content=\"You have code now\")\n",
    "        return {\"code\": new_message, \"messages\": [new_message]}\n",
    "    elif tool == \"Review Code\":\n",
    "        print(\"successfully reviewing code now\")\n",
    "        new_message = AIMessage(content=\"Code is approved\")\n",
    "        return {\"code_approved\": True, \"messages\": [new_message]}\n",
    "    elif tool == \"Save Code\":\n",
    "        print(\"Save Code\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define a new graph\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"action\", call_tool)\n",
    "graph.add_node(\"initial_state\", call_set_initial_state)\n",
    "\n",
    "# Set the entrypoint\n",
    "graph.set_entry_point(\"initial_state\")\n",
    "\n",
    "# Add a conditional edge\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Aadd the Normal Edges\n",
    "graph.add_edge(\"action\", \"agent\")\n",
    "graph.add_edge(\"initial_state\", \"agent\")\n",
    "\n",
    "# Compile it\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'initial_state':\n",
      "---\n",
      "{'original_request': '\\nCreate a chain that does the following:\\n- Accept a string named answer as input\\n- Format a System and Human message using templates. The System message has output instructions via Pydantic. The Human message uses answer as context. Output instructions should require format to a Pydantic schema for hmw_question with a question (up to 10 words) and a role (either CMO, CTO, or CEO) \\n- Pass the messages to OpenAI\\n- Parse the response using Pydantic\\n'}\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'agent_runnable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m      3\u001b[0m feature_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mCreate a chain that does the following:\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m- Accept a string named answer as input\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m- Parse the response using Pydantic\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39mfeature_request)]}\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mstream(inputs):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# stream() yields dictionaries with output keyed by node name\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput from node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langgraph\\pregel\\__init__.py:615\u001b[0m, in \u001b[0;36mPregel.transform\u001b[1;34m(self, input, config, output_keys, input_keys, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    614\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]]:\n\u001b[1;32m--> 615\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m    616\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m    618\u001b[0m         config,\n\u001b[0;32m    619\u001b[0m         output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m    620\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39minput_keys,\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    622\u001b[0m     ):\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_core\\runnables\\base.py:1497\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1497\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langgraph\\pregel\\__init__.py:355\u001b[0m, in \u001b[0;36mPregel._transform\u001b[1;34m(self, input, run_manager, config, input_keys, output_keys, interrupt)\u001b[0m\n\u001b[0;32m    348\u001b[0m done, inflight \u001b[38;5;241m=\u001b[39m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mwait(\n\u001b[0;32m    349\u001b[0m     futures,\n\u001b[0;32m    350\u001b[0m     return_when\u001b[38;5;241m=\u001b[39mconcurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFIRST_EXCEPTION,\n\u001b[0;32m    351\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m    352\u001b[0m )\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# interrupt on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[43m_interrupt_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# apply writes to channels\u001b[39;00m\n\u001b[0;32m    358\u001b[0m _apply_writes(\n\u001b[0;32m    359\u001b[0m     checkpoint, channels, pending_writes, config, step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    360\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langgraph\\pregel\\__init__.py:698\u001b[0m, in \u001b[0;36m_interrupt_or_proceed\u001b[1;34m(done, inflight, step)\u001b[0m\n\u001b[0;32m    696\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[1;32m--> 698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    699\u001b[0m         \u001b[38;5;66;03m# TODO this is where retry of an entire step would happen\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_core\\runnables\\base.py:4064\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4058\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   4059\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4060\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   4061\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4062\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   4063\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 4064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   4065\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4066\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   4067\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   4068\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_core\\runnables\\base.py:2053\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2051\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2052\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2053\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2056\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2059\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2060\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   2061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_core\\runnables\\base.py:3507\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3505\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 3507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   3508\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   3509\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3510\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config(config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[0;32m   3511\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3512\u001b[0m     )\n\u001b[0;32m   3513\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3515\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3516\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3517\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_core\\runnables\\base.py:1246\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1243\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[0;32m   1244\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1245\u001b[0m         Output,\n\u001b[1;32m-> 1246\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1247\u001b[0m             call_func_with_variable_args,\n\u001b[0;32m   1248\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m             config,\n\u001b[0;32m   1251\u001b[0m             run_manager,\n\u001b[0;32m   1252\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1253\u001b[0m         ),\n\u001b[0;32m   1254\u001b[0m     )\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1256\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_core\\runnables\\config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    325\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_core\\runnables\\base.py:3383\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3381\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   3382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3383\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   3384\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   3385\u001b[0m     )\n\u001b[0;32m   3386\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[0;32m   3387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32mc:\\Users\\28263\\anaconda3\\lib\\site-packages\\langchain_core\\runnables\\config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    325\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mcall_model\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_model\u001b[39m(state):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# messages = state['messages']\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     agent_outcome \u001b[38;5;241m=\u001b[39m \u001b[43magent_runnable\u001b[49m\u001b[38;5;241m.\u001b[39minvoke(state)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_outcome\u001b[39m\u001b[38;5;124m\"\u001b[39m: agent_outcome}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_runnable' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "feature_request = \"\"\"\n",
    "Create a chain that does the following:\n",
    "- Accept a string named answer as input\n",
    "- Format a System and Human message using templates. The System message has output instructions via Pydantic. The Human message uses answer as context. Output instructions should require format to a Pydantic schema for hmw_question with a question (up to 10 words) and a role (either CMO, CTO, or CEO) \n",
    "- Pass the messages to OpenAI\n",
    "- Parse the response using Pydantic\n",
    "\"\"\"\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=feature_request)]}\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
